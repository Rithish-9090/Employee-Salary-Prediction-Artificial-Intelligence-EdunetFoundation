import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_curve, auc

# --- 1. Load and Clean the Data ---
# Load the dataset and directly replace '?' values and drop the 'education' column.
data = pd.read_excel("/content/adult 3.csv.xlsx")
data['workclass'] = data['workclass'].replace({'?': 'Others'})
data['occupation'] = data['occupation'].replace({'?': 'Others'})
data = data.drop(columns=['education'])

# --- 2. Encode Categorical Features ---
# Convert each text column to numbers individually.
le = LabelEncoder()
data['workclass'] = le.fit_transform(data['workclass'])
data['marital-status'] = le.fit_transform(data['marital-status'])
data['occupation'] = le.fit_transform(data['occupation'])
data['relationship'] = le.fit_transform(data['relationship'])
data['race'] = le.fit_transform(data['race'])
data['gender'] = le.fit_transform(data['gender'])
data['native-country'] = le.fit_transform(data['native-country'])
data['income'] = le.fit_transform(data['income'])

# --- 3. Split and Scale the Data ---
# Define features (X) and target (y), then split into training and testing sets.
X = data.drop(columns=['income'])
y = data['income']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Scale the features.
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# --- 4. Logistic Regression: Train, Evaluate, and Plot ---
print("\n--- Training Logistic Regression ---")
lr_model = LogisticRegression()
lr_model.fit(X_train, y_train)

# Make predictions and get the accuracy.
lr_predictions = lr_model.predict(X_test)
lr_accuracy = accuracy_score(y_test, lr_predictions)
print(f"Accuracy: {lr_accuracy:.4f}")
print(classification_report(y_test, lr_predictions))

# Generate and display the Confusion Matrix.
lr_cm = confusion_matrix(y_test, lr_predictions)
plt.figure(figsize=(6, 5))
sns.heatmap(lr_cm, annot=True, fmt="d", cmap="Blues")
plt.title("Logistic Regression - Confusion Matrix")
plt.ylabel("Actual")
plt.xlabel("Predicted")
plt.show()

# Generate and display the ROC Curve.
lr_probas = lr_model.predict_proba(X_test)[:, 1]
fpr, tpr, _ = roc_curve(y_test, lr_probas)
roc_auc = auc(fpr, tpr)
plt.figure(figsize=(6, 5))
plt.plot(fpr, tpr, label=f"AUC = {roc_auc:.2f}", color="darkorange")
plt.plot([0, 1], [0, 1], linestyle='--', color='navy')
plt.title("Logistic Regression - ROC Curve")
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.legend()
plt.grid(True)
plt.show()


# --- 5. Random Forest: Train, Evaluate, and Plot ---
print("\n--- Training Random Forest ---")
rf_model = RandomForestClassifier()
rf_model.fit(X_train, y_train)

# Make predictions and get the accuracy.
rf_predictions = rf_model.predict(X_test)
rf_accuracy = accuracy_score(y_test, rf_predictions)
print(f"Accuracy: {rf_accuracy:.4f}")
print(classification_report(y_test, rf_predictions))

# Generate and display the Confusion Matrix.
rf_cm = confusion_matrix(y_test, rf_predictions)
plt.figure(figsize=(6, 5))
sns.heatmap(rf_cm, annot=True, fmt="d", cmap="Greens")
plt.title("Random Forest - Confusion Matrix")
plt.ylabel("Actual")
plt.xlabel("Predicted")
plt.show()

# Generate and display the ROC Curve.
rf_probas = rf_model.predict_proba(X_test)[:, 1]
fpr, tpr, _ = roc_curve(y_test, rf_probas)
roc_auc = auc(fpr, tpr)
plt.figure(figsize=(6, 5))
plt.plot(fpr, tpr, label=f"AUC = {roc_auc:.2f}", color="darkgreen")
plt.plot([0, 1], [0, 1], linestyle='--', color='navy')
plt.title("Random Forest - ROC Curve")
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.legend()
plt.grid(True)
plt.show()

# --- 6. Compare Model Accuracies ---
# Create a bar chart comparing the accuracy of the two models.
model_names = ["Logistic Regression", "Random Forest"]
accuracies = [lr_accuracy, rf_accuracy]

plt.figure(figsize=(8, 6))
plt.bar(model_names, accuracies, color=['skyblue', 'lightgreen'])
plt.ylabel("Accuracy Score")
plt.title("Model Accuracy Comparison")
plt.ylim(0.8, 0.9)
plt.text(0, lr_accuracy + 0.002, f'{lr_accuracy:.4f}', ha='center', fontsize=12)
plt.text(1, rf_accuracy + 0.002, f'{rf_accuracy:.4f}', ha='center', fontsize=12)
plt.show()
